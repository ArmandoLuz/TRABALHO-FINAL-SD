# ğŸ§  THREE NODE PASID-VALIDATOR

Este projeto simula um sistema distribuÃ­do composto por mÃºltiplos serviÃ§os e 
dois balanceadores de carga, utilizando Docker e Python. A aplicaÃ§Ã£o envolve o 
envio de mensagens por um componente **source**. As mensagens percorrem dois nÃ­veis 
de balanceadores, onde cada balanceador distribui as mensagens por dois serviÃ§os.
Cada serviÃ§o, por sua vez, processa imagens usando um modelo de IA embarcado. As imagens em
questÃ£o sÃ£o processadas sempre que uma mensagem chega em seu nÃ³, e os resultados do
processamento sÃ£o armazenados em logs individuais. No Ãºltimo nÃ­vel, a mensagem 
retorna de volta a origem, onde o **source** registra o tempo mÃ©dio de resposta.

## ğŸ“Œ Arquitetura do Sistema

![Arquitetura do SD](assets/pasid.png)

- **SOURCE**: Origem das mensagens (Gatilhos para o processamento das imagens).
- **LOAD BALANCER**: Balanceadores de carga que distribuem as mensagens para os serviÃ§os.
- **SERVICES**: ServiÃ§os que processam as imagens usando IA sempre que recebem uma mensagem.

## ğŸ“ Estrutura de Pastas do projeto.

```
.
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ source/
â”‚   â””â”€â”€ source.py # CÃ³digo do SOURCE 
|   â”œâ”€â”€ Dockerfile
â”œâ”€â”€ load_balancer/
â”‚   â””â”€â”€ load_balancer.py # CÃ³digo dos balanceadores de carga
â”‚   â”œâ”€â”€ Dockerfile
â”œâ”€â”€ service/
â”‚   â”œâ”€â”€ service.py # CÃ³digo dos serviÃ§os que processam as imagens
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ data/ # Imagens para processamento
â”œâ”€â”€ logs/ # Logs individuais de cada host
    â”œâ”€â”€ source/
    â”œâ”€â”€ lb1/
    â”œâ”€â”€ lb2/
    â”œâ”€â”€ service1/
    â”œâ”€â”€ service2/
    â”œâ”€â”€ service3/
    â””â”€â”€ service4/
```

## âš™ï¸ Tecnologias Utilizadas

- Python 3.12
- Docker e Docker Compose
- Sockets TCP
- Tensorflow
- Numpy e Pillow
- MobileNetV2 (IA embarcada nos serviÃ§os)
- Balanceamento de carga simples (round-robin)

## ğŸ“¦ Requisitos

- Docker
- Docker Compose

## ğŸš€ Como Executar o Projeto

1. Clone o repositÃ³rio:

```bash
git clone https://github.com/ArmandoLuz/TRABALHO-FINAL-SD.git
cd TRABALHO-FINAL-SD
```

2. Execute o projeto com Docker Compose:

```bash
docker compose up --build
```

3. O sistema iniciarÃ¡ os seguintes containers:

- `source`
- `lb1`
- `lb2`
- `service1`
- `service2`
- `service3`
- `service4`

4. Os logs de cada componente estarÃ£o disponÃ­veis nas pastas correspondentes dentro de `logs/`.

## ğŸ”§ VariÃ¡veis de Ambiente (exemplo do LB1)
Algumas configuraÃ§Ãµes podem ser ajustadas atravÃ©s de variÃ¡veis de ambiente de cada container:

- `LISTEN_HOST=0.0.0.0` # Define o endereÃ§o de escuta do LB1.
- `LISTEN_PORT=4000` # Define a porta de escuta do LB1.
- `SERVERS=service1:5000,service2:5001` # Define os serviÃ§os que o LB1 irÃ¡ distribuir as mensagens.
- `LB_ID=1` # Identificador do balanceador de carga (LB-1).

## Resultados de experimentos

Este experimento teve como objetivo avaliar o desempenho de um sistema distribuÃ­do sob diferentes nÃ­veis de paralelismo, simulando a 
variaÃ§Ã£o do nÃºmero de serviÃ§os responsÃ¡veis pelo processamento de mensagens. Para isso, mensurou-se o tempo mÃ©dio de resposta (MRT) e 
seu desvio padrÃ£o (STD) em funÃ§Ã£o da carga, representada pelo nÃºmero de mensagens processadas por segundo. TrÃªs configuraÃ§Ãµes distintas 
foram analisadas, com 5, 6 e 7 serviÃ§os ativos e com variadas taxas de geraÃ§Ã£o de mensagens (1 a 10 mensagens por segundo). O MRT reflete a eficiÃªncia do sistema, enquanto o STD indica sua estabilidade.

![MRT](assets/mrt.png)

![STD](assets/std.png)

A anÃ¡lise dos grÃ¡ficos revela um comportamento crescente do tempo mÃ©dio de resposta (MRT) Ã  medida que o nÃºmero de mensagens por segundo aumenta, independentemente da quantidade de serviÃ§os disponÃ­veis. No entanto, observa-se que o ritmo desse crescimento Ã© fortemente influenciado pelo grau de paralelismo oferecido pelo sistema.

Para o cenÃ¡rio com 5 serviÃ§os, o MRT apresenta um crescimento mais acelerado, ultrapassando 2800 ms com 10 mensagens/s, enquanto o mesmo volume de mensagens resulta em 2300 ms com 6 serviÃ§os e 1870 ms com 7 serviÃ§os. Essa diferenÃ§a destaca a importÃ¢ncia da escalabilidade: o aumento no nÃºmero de serviÃ§os permite distribuir melhor a carga de trabalho, resultando em tempos de resposta menores sob condiÃ§Ãµes de estresse.

AlÃ©m disso, os grÃ¡ficos de desvio padrÃ£o indicam que a variabilidade do tempo de resposta tambÃ©m Ã© reduzida com mais serviÃ§os. Com 5 serviÃ§os, os desvios padrÃ£o chegam a 100 ms nos piores casos, enquanto com 7 serviÃ§os esse valor Ã© significativamente menor (55 ms), evidenciando um sistema mais estÃ¡vel e previsÃ­vel. A presenÃ§a de picos de variaÃ§Ã£o mais acentuados em configuraÃ§Ãµes com menos serviÃ§os reforÃ§a o impacto negativo da saturaÃ§Ã£o prematura.

Outro ponto notÃ¡vel nos grÃ¡ficos Ã© que, para cargas mais baixas (entre 1 e 5 mensagens/s), os tempos de resposta e suas variaÃ§Ãµes sÃ£o semelhantes entre os trÃªs cenÃ¡rios, indicando que todos operam de forma eficiente quando a carga Ã© reduzida. Contudo, Ã  medida que o nÃºmero de mensagens aumenta, as diferenÃ§as entre as curvas tornam-se mais pronunciadas, e os benefÃ­cios da escalabilidade se tornam evidentes tanto em desempenho mÃ©dio quanto em estabilidade.
AlÃ©m disso, Ã© vÃ¡lido evidenciar que atÃ© 5 mensagens por segundo, Ã© previsÃ­vel que o sistema opere de forma semelhante nos 3 casos, jÃ¡ que a carga serÃ¡ balanceada entre os 5 hosts na configuraÃ§Ã£o mais fraca. ApÃ³s esse valor, as diferenÃ§as entre os sistsemas se tornam mais evidentes, com o sistema com 7 serviÃ§os apresentando uma performance superior, tanto em termos de tempo mÃ©dio de resposta quanto de estabilidade.

Em resumo, os grÃ¡ficos deixam claro que a adiÃ§Ã£o de serviÃ§os reduz significativamente o tempo de resposta e suaviza a variabilidade do sistema, tornando-o mais robusto e confiÃ¡vel sob cargas crescentes.